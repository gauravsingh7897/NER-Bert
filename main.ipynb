{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA_8tNSD5Qv7",
        "outputId": "abbd02cf-2bf1-404c-b2a0-46c772a5dd8e"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgzT5pW85GqT"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import transformers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-r6DbMx5Gqj"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/gauravsingh7897/NER-Bert/main/ner_dataset.csv\", encoding='latin1').fillna(method='ffill')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7njxEfO45Gqk",
        "outputId": "65fc9792-2c45-4bfd-a161-97c669db871c"
      },
      "source": [
        "df.info(), len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPf2K9tv5Gqn"
      },
      "source": [
        "enc_tag = LabelEncoder()\n",
        "df['Tag'] = enc_tag.fit_transform(df['Tag'])\n",
        "tag_unique = enc_tag.classes_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbVJZ5ne5Gqo",
        "outputId": "43bff66f-9923-4881-9d95-18d5b963ec45"
      },
      "source": [
        "tag_unique"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QoPa8uz5Gqp"
      },
      "source": [
        "def preprocess(data):\n",
        "    tags      = data.groupby('Sentence #')['Tag'].apply(list).values\n",
        "    sentences = data.groupby('Sentence #')['Word'].apply(list).values\n",
        "    return sentences, tags\n",
        "sentences, tags = preprocess(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31PiLPoG5Gqq"
      },
      "source": [
        "train_sentences, test_sentences, train_tags, test_tags = train_test_split(sentences, tags, test_size=0.15, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64fR_4UY5Gqr"
      },
      "source": [
        "class NERDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, sentences, tags):\n",
        "        super(NERDataset, self).__init__()\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.max_len = 256\n",
        "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        tag = self.tags[idx]\n",
        "\n",
        "        ids  = []\n",
        "        tags = []\n",
        "        for idx, word in enumerate(sentence):\n",
        "            encoding = self.tokenizer.encode(word,add_special_tokens=False, max_length=self.max_len, truncation=True)\n",
        "            ids.extend(encoding)\n",
        "            tags.extend([tag[idx]] * len(encoding))\n",
        "        \n",
        "        ids = [101] + ids + [102]\n",
        "        masks = [1] * len(ids) \n",
        "        token_type_ids = [0] * len(ids)\n",
        "        tags = [0] + tags + [0]\n",
        "\n",
        "        pad_len = self.max_len - len(ids)\n",
        "\n",
        "        if pad_len > 0:\n",
        "            ids = ids + [0] * pad_len\n",
        "            masks = masks + [0] * pad_len\n",
        "            token_type_ids = token_type_ids + [0] * pad_len\n",
        "            tags = tags + [0] * pad_len\n",
        "        \n",
        "        return {\n",
        "            \"ids\" : torch.tensor(ids, dtype=torch.long),\n",
        "            \"masks\" : torch.tensor(masks, dtype=torch.long),\n",
        "            \"token_type_ids\" : torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            \"tags\" : torch.tensor(tags, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvh0szMt5Gqs"
      },
      "source": [
        "train_dataset = NERDataset(train_sentences, train_tags)\n",
        "test_dataset   = NERDataset(test_sentences, test_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f0pwQ7D5Gqt"
      },
      "source": [
        "train_data_loader = torch.utils.data.DataLoader(train_dataset, num_workers=0, batch_size=16)\n",
        "test_data_loader  = torch.utils.data.DataLoader(test_dataset, num_workers=0, batch_size=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYZcrpbk5Gqu",
        "outputId": "c0f56d34-da76-4cc0-ecaf-f02a61dfca5e"
      },
      "source": [
        "model = transformers.BertForTokenClassification.from_pretrained(\"bert-base-uncased\",num_labels=len(tag_unique))\n",
        "device = torch.device('cuda')\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvNvN18q5Gqu"
      },
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=3e-5, eps=1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsV8ugc65Gqv"
      },
      "source": [
        "total_steps = int(len(train_sentences) / 16 * 10)\n",
        "\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIdvkumj5Gqw"
      },
      "source": [
        "def train(model, data_loader, optimizer, schedular, device):\n",
        "    model.train()\n",
        "\n",
        "    total_train_loss = 0\n",
        "    for data in tqdm(data_loader, total=len(data_loader)):\n",
        "        ids            = data['ids']\n",
        "        masks          = data['masks']\n",
        "        token_type_ids = data['token_type_ids']\n",
        "        tags           = data['tags']\n",
        "\n",
        "        ids = ids.to(device)\n",
        "        masks = masks.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        tags = tags.to(device)\n",
        "\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(ids, attention_mask=masks, token_type_ids=token_type_ids, labels=tags)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(data_loader)\n",
        "    print(f\"Average Train Loss : {avg_train_loss}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vHsHOp95Gqx"
      },
      "source": [
        "def test(model, data_loader, device):\n",
        "    model.eval()\n",
        "\n",
        "    total_test_loss = 0\n",
        "    logits = []\n",
        "    labels = []\n",
        "\n",
        "    for data in tqdm(data_loader, total=len(data_loader)):\n",
        "        ids            = data['ids']\n",
        "        masks          = data['masks']\n",
        "        token_type_ids = data['token_type_ids']\n",
        "        tags           = data['tags']\n",
        "\n",
        "        ids = ids.to(device)\n",
        "        masks = masks.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        tags = tags.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(ids, attention_mask=masks, token_type_ids=token_type_ids, labels=tags)\n",
        "\n",
        "        loss   = outputs[0]\n",
        "\n",
        "        logits.extend(np.argmax(outputs[1].cpu().detach().numpy(), axis=-1).flatten())\n",
        "        labels.extend(tags.cpu().detach().numpy().flatten())\n",
        "        total_test_loss += loss.item()\n",
        "\n",
        "    avg_test_loss = total_test_loss / len(data_loader)\n",
        "    print(f\"Average Test Loss : {avg_test_loss}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pYpx29FZ5Gqy",
        "outputId": "55bb2211-0926-46ed-ad08-a7f853c6dae4"
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "for i in range(10):\n",
        "    print(f\"Epoch : {i+1}\")\n",
        "    train(model, train_data_loader, optimizer, scheduler, device)\n",
        "    test(model, test_data_loader, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgz74pVUYXBR"
      },
      "source": [
        "test_data = test_dataset.__getitem__(0)\r\n",
        "test_out = model(torch.unsqueeze(test_data['ids'].to(device), 0),attention_mask=torch.unsqueeze(test_data['masks'].to(device), 0), token_type_ids=torch.unsqueeze(test_data['token_type_ids'].to(device), 0))\r\n",
        "logits = np.argmax(test_out[0].cpu().detach().numpy(), axis=-1).flatten()\r\n",
        "labels = test_data['tags'].cpu().detach().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cgc1EGY4i5K",
        "outputId": "e781f55e-b9da-4ccd-8ca2-0b37dc6e9755"
      },
      "source": [
        "logits, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14emCvgi7EKg",
        "outputId": "dada996f-387b-47e7-e589-76ec2a6ceebf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC9skFmG6MDT"
      },
      "source": [
        "torch.save(model.state_dict(), \"drive/MyDrive/saved_model.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}